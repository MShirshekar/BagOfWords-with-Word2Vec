{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.22.4)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from spacy) (8.0.17)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: setuptools in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from spacy) (57.0.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.28.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from spacy) (0.7.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (1.22.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (1.8.1)\n",
      "Requirement already satisfied: Cython==0.29.28 in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (from gensim) (0.29.28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (f:\\projects\\pycharmprojects\\pythoninterpreter\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install spacy\n",
    "!pip install gensim\n",
    "!pip install tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['F:\\\\Programes\\\\JetBrains\\\\PyCharm 2021.3.1\\\\plugins\\\\python\\\\helpers-pro\\\\jupyter_debug',\n 'F:\\\\Programes\\\\JetBrains\\\\PyCharm 2021.3.1\\\\plugins\\\\python\\\\helpers\\\\pydev',\n 'F:\\\\Projects\\\\PycharmProjects\\\\Bag of words with Word2Vec',\n 'F:\\\\Projects\\\\PycharmProjects\\\\Bag of words with Word2Vec',\n 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\python310.zip',\n 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\DLLs',\n 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib',\n 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310',\n '',\n 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages',\n 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages\\\\win32',\n 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages\\\\win32\\\\lib',\n 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages\\\\Pythonwin',\n 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages',\n 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\win32',\n 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\win32\\\\lib',\n 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\Pythonwin',\n 'F:\\\\Projects\\\\PycharmProjects\\\\PythonInterpreter\\\\Lib\\\\site-packages']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.path.dirname(\"F:\\Projects\\PycharmProjects\\PythonInterpreter\\Lib\\site-packages\"), \"site-packages\"))\n",
    "os.sys.path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 171,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Essay Clustering Algorithm #Cluster based on Key Identification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "   0  1\n0  0  0\n1  1  1\n2  1  2\n3  0  2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame([[0,0],[1,1],[1,2],[0,2]])\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x23c52f92a10>]"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "N = len(data)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(data[0], data[1], 'rs')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1         2         3\n0  0.000000  1.414214  2.236068  2.000000\n1  1.414214  0.000000  1.000000  1.414214\n2  2.236068  1.000000  0.000000  1.000000\n3  2.000000  1.414214  1.000000  0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>1.414214</td>\n      <td>2.236068</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.414214</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.414214</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.236068</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.000000</td>\n      <td>1.414214</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "D_orginal = pd.DataFrame(pairwise_distances(data))\n",
    "D_orginal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 0, 3]"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def R(p_index,k_index):\n",
    "    R_p = []\n",
    "    if k_index == 0:\n",
    "        return []\n",
    "    for p in range(N):\n",
    "        a = []\n",
    "        for k in range(N-1):\n",
    "            list_index = [i for i in D_orginal.loc[p].sort_values().drop(index=p).index[0:k+1]]\n",
    "            a.append(list_index)\n",
    "        R_p.append(a)\n",
    "    return R_p[p_index][k_index-1]\n",
    "R(1,3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k = 3\n",
    "g = 2\n",
    "L = [i for i in range(N)]\n",
    "C_previous = N\n",
    "C_current = N/g\n",
    "D_current = D_orginal\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        a = 1 / np.power(k+1, 2)\n",
    "        b = D_orginal[i][j]\n",
    "        D_current[i][j] = a * b\n",
    "D_current"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    if i not in key_elements:\n",
    "        L[i] = D_current[L[i]][j].min()\n",
    "L"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in key_elements:\n",
    "    for j in key_elements:\n",
    "        # a = 1 / len(key_elements[i]) * len(key_elements[j])\n",
    "        a = 1\n",
    "        b = D_orginal[i][j]\n",
    "        D_current[i][j] = a * b\n",
    "D_current"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "C_previous = C_current\n",
    "C_current = C_current/g"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Key Identification step"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "   index      mean\n0      1  0.957107\n1      2  1.059017\n2      3  1.103553\n3      0  1.412570",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.957107</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.059017</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.103553</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1.412570</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = []\n",
    "for i in range(N):\n",
    "    list.append(D_orginal[i].mean())\n",
    "mean = pd.DataFrame({'mean':list}).sort_values(by='mean').reset_index()\n",
    "mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0]\n",
      "[1, 0, 3]\n",
      "[1, 0, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "c = 4\n",
    "I1 = mean['index'][0]\n",
    "n = 1\n",
    "S = {I1}\n",
    "key_elements = [*S, ]\n",
    "if c == n:\n",
    "    None\n",
    "else:\n",
    "    K1 = [i for i in range(N) if i != I1]\n",
    "    I = D_orginal[I1].sort_values(ascending=False).index[0]\n",
    "    K = [i for i in K1 if i != I]\n",
    "    n +=1\n",
    "    S.add(I)\n",
    "    key_elements.append(I)\n",
    "    while n != c:\n",
    "\n",
    "        index = []\n",
    "        sim = []\n",
    "        for p in range(N):\n",
    "            if p not in S:\n",
    "                index.append(p)\n",
    "                sim.append(min([D_orginal[p][i] for i in range(N) if S.intersection({i}) != set()]) )\n",
    "        remain_data = pd.DataFrame({'index':index,'sim':sim}).sort_values(by='sim',ascending=False).reset_index()\n",
    "\n",
    "        I = remain_data['index'][0]\n",
    "        print(key_elements)\n",
    "        K = [i for i in K if i != I]\n",
    "        S.add(I)\n",
    "        key_elements.append(I)\n",
    "        n += 1\n",
    "    else:\n",
    "        print(key_elements)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key item 1: [1 1]\n",
      "Key item 2: [0 0]\n",
      "Key item 3: [0 2]\n",
      "Key item 4: [1 2]\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "for key in key_elements:\n",
    "    print(f'Key item {index}: {data.loc[key].values}')\n",
    "    index += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classify Reddit users' comments with BagOfWord + Word2Vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## read train and test datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def load_data(path):\n",
    "    return pd.read_csv(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (8695, 3)\n",
      "Train Data Valeus: ['Id' 'Comment' 'Topic']\n",
      "Test Data Shape: (1586, 3)\n",
      "Test Data Valeus: ['Id' 'Comment' 'Topic']\n"
     ]
    }
   ],
   "source": [
    "# Train Data\n",
    "train_data = load_data(path = 'train.csv')\n",
    "print('Train Data Shape:', train_data.shape)\n",
    "print('Train Data Valeus:', train_data.columns.values)\n",
    "\n",
    "# Test Data\n",
    "test_data = load_data(path = 'test.csv')\n",
    "print('Test Data Shape:', test_data.shape)\n",
    "print('Test Data Valeus:', test_data.columns.values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## check missing value and duplicate record"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** train's attribute [] has *Duplicated* records ***\n",
      "\n",
      "*** test's attribute [] has *Duplicated* records ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import compress\n",
    "\n",
    "# Convert space value in *content* attribute to NaN value.\n",
    "for i in range(1,len(train_data)):\n",
    "    if train_data['Topic'][i] == ' ':\n",
    "        train_data['Topic'][i] = None\n",
    "\n",
    "for i in range(1,len(test_data)):\n",
    "    if test_data['Topic'][i] == ' ':\n",
    "        test_data['Topic'][i] = None\n",
    "\n",
    "\n",
    "# Check Duplicated records\n",
    "duplicate = train_data.duplicated()\n",
    "duplicate_index = list(compress(range(len(duplicate)), duplicate))\n",
    "print(f\"*** train's attribute {duplicate_index} has *Duplicated* records ***\\n\")\n",
    "\n",
    "duplicate = test_data.duplicated()\n",
    "duplicate_index = list(compress(range(len(duplicate)), duplicate))\n",
    "print(f\"*** test's attribute {duplicate_index} has *Duplicated* records ***\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8695 entries, 0 to 8694\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Id       8695 non-null   object\n",
      " 1   Comment  8695 non-null   object\n",
      " 2   Topic    8695 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 203.9+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1586 entries, 0 to 1585\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Id       1586 non-null   object\n",
      " 1   Comment  1586 non-null   object\n",
      " 2   Topic    1586 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 37.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_data.info())\n",
    "print(test_data.info())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "          Id                                            Comment      Topic\n0      0x840  A few things. You might have negative- frequen...    Biology\n1      0xbf0  Is it so hard to believe that there exist part...    Physics\n2     0x1dfc                                     There are bees    Biology\n3      0xc7e  I'm a medication technician. And that's alot o...    Biology\n4      0xbba                     Cesium is such a pretty metal.  Chemistry\n...      ...                                                ...        ...\n8690  0x1e02  I make similar observations over the last week...    Biology\n8691   0xc8d                                    You would know.    Biology\n8692   0x723            Also use the correct number of sig figs  Chemistry\n8693   0x667  What about the ethical delimmas,  groundbreaki...    Biology\n8694  0x1476                          I would like to know too.    Biology\n\n[8695 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Comment</th>\n      <th>Topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x840</td>\n      <td>A few things. You might have negative- frequen...</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0xbf0</td>\n      <td>Is it so hard to believe that there exist part...</td>\n      <td>Physics</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x1dfc</td>\n      <td>There are bees</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0xc7e</td>\n      <td>I'm a medication technician. And that's alot o...</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0xbba</td>\n      <td>Cesium is such a pretty metal.</td>\n      <td>Chemistry</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8690</th>\n      <td>0x1e02</td>\n      <td>I make similar observations over the last week...</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>8691</th>\n      <td>0xc8d</td>\n      <td>You would know.</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>8692</th>\n      <td>0x723</td>\n      <td>Also use the correct number of sig figs</td>\n      <td>Chemistry</td>\n    </tr>\n    <tr>\n      <th>8693</th>\n      <td>0x667</td>\n      <td>What about the ethical delimmas,  groundbreaki...</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>8694</th>\n      <td>0x1476</td>\n      <td>I would like to know too.</td>\n      <td>Biology</td>\n    </tr>\n  </tbody>\n</table>\n<p>8695 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "          Id                                            Comment      Topic\n0     0x1aa9  Personally I have no idea what my IQ is. I’ve ...    Biology\n1      0x25e  I'm skeptical. A heavier lid would be needed t...    Physics\n2     0x1248  I think I have 100 cm of books on the subject....    Biology\n3      0x2b9  Is chemistry hard in uni. Ive read somewhere t...  Chemistry\n4     0x24af  In addition to the other comment, you can crit...    Physics\n...      ...                                                ...        ...\n1581  0x22bf  I’m not really denying your intent. I’m a) dou...  Chemistry\n1582  0x1f4a  i really empathize with your compassion for bu...    Biology\n1583  0x27b7  If you want to keep it for more than 2 weeks, ...  Chemistry\n1584  0x2066  Same here. I’m in nursing school so I only hav...    Biology\n1585   0x6d6  The video basically says read a pop-sci book a...    Physics\n\n[1586 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Comment</th>\n      <th>Topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x1aa9</td>\n      <td>Personally I have no idea what my IQ is. I’ve ...</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0x25e</td>\n      <td>I'm skeptical. A heavier lid would be needed t...</td>\n      <td>Physics</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x1248</td>\n      <td>I think I have 100 cm of books on the subject....</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0x2b9</td>\n      <td>Is chemistry hard in uni. Ive read somewhere t...</td>\n      <td>Chemistry</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x24af</td>\n      <td>In addition to the other comment, you can crit...</td>\n      <td>Physics</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1581</th>\n      <td>0x22bf</td>\n      <td>I’m not really denying your intent. I’m a) dou...</td>\n      <td>Chemistry</td>\n    </tr>\n    <tr>\n      <th>1582</th>\n      <td>0x1f4a</td>\n      <td>i really empathize with your compassion for bu...</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>1583</th>\n      <td>0x27b7</td>\n      <td>If you want to keep it for more than 2 weeks, ...</td>\n      <td>Chemistry</td>\n    </tr>\n    <tr>\n      <th>1584</th>\n      <td>0x2066</td>\n      <td>Same here. I’m in nursing school so I only hav...</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>1585</th>\n      <td>0x6d6</td>\n      <td>The video basically says read a pop-sci book a...</td>\n      <td>Physics</td>\n    </tr>\n  </tbody>\n</table>\n<p>1586 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## natural language preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Get stopwords list\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "custom_stop_words = {'br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\",\n",
    "                     \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his',\n",
    "                     'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them',\n",
    "                     'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\",\n",
    "                     'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n",
    "                     'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because',\n",
    "                     'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "                     'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out',\n",
    "                     'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where',\n",
    "                     'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only',\n",
    "                     'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\",\n",
    "                     'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\",\n",
    "                     'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\",\n",
    "                     'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn',\n",
    "                     \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won',\n",
    "                     \"won't\", 'wouldn', \"wouldn't\", \"interesting\", \"interest\", \"also\", \"could\", \"would\"}\n",
    "\n",
    "def cleanup(review):\n",
    "\n",
    "    # Remove Markups or HTML tags\n",
    "    review =  BeautifulSoup(review).get_text()\n",
    "\n",
    "    # Remove Numbers\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "\n",
    "    # Remove words with numbers for exp: 'A55D'\n",
    "    review = re.sub(\"\\S*\\d\\S*\", \" \", review).strip()\n",
    "\n",
    "    # Convert to lowercase\n",
    "    review = review.lower()\n",
    "\n",
    "    #Tokenize\n",
    "    word_tokens = word_tokenize(review)\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_tokens = [lemmatizer.lemmatize(token) for token in word_tokens]\n",
    "\n",
    "    # Stemming\n",
    "    # stemmer = PorterStemmer()\n",
    "    # word_tokens = [stemmer.stem(word) for word in word_tokens]\n",
    "\n",
    "    # Remove stop words\n",
    "    review = [word for word in word_tokens if not word in stop_words and not len(word)<3\n",
    "              and not word in custom_stop_words]\n",
    "\n",
    "    # Rejoin the review words into one string\n",
    "    review = ' '.join(review)\n",
    "\n",
    "    # Remove repeated characters\n",
    "    review = re.sub(r'(.)\\1{2,}',' ', review)\n",
    "\n",
    "    return review\n",
    "\n",
    "def process_data(data, data_type):\n",
    "\n",
    "    # Create a new DataFrame\n",
    "    cleaned_data = data.copy()\n",
    "\n",
    "    reviews = []\n",
    "    for i, review in enumerate(data['Comment']):\n",
    "        cleaned_review = cleanup(review)\n",
    "        reviews.append(cleaned_review)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f'Processing \"{data_type}\", {i} Review...')\n",
    "\n",
    "    cleaned_data['Comment'] = reviews\n",
    "\n",
    "    return cleaned_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing \"Train Data\", 0 Review...\n",
      "Processing \"Train Data\", 100 Review...\n",
      "Processing \"Train Data\", 200 Review...\n",
      "Processing \"Train Data\", 300 Review...\n",
      "Processing \"Train Data\", 400 Review..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\__init__.py:404: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing \"Train Data\", 500 Review...\n",
      "Processing \"Train Data\", 600 Review...\n",
      "Processing \"Train Data\", 700 Review...\n",
      "Processing \"Train Data\", 800 Review...\n",
      "Processing \"Train Data\", 900 Review...\n",
      "Processing \"Train Data\", 1000 Review...\n",
      "Processing \"Train Data\", 1100 Review...\n",
      "Processing \"Train Data\", 1200 Review...\n",
      "Processing \"Train Data\", 1300 Review...\n",
      "Processing \"Train Data\", 1400 Review...\n",
      "Processing \"Train Data\", 1500 Review...\n",
      "Processing \"Train Data\", 1600 Review...\n",
      "Processing \"Train Data\", 1700 Review...\n",
      "Processing \"Train Data\", 1800 Review...\n",
      "Processing \"Train Data\", 1900 Review...\n",
      "Processing \"Train Data\", 2000 Review...\n",
      "Processing \"Train Data\", 2100 Review...\n",
      "Processing \"Train Data\", 2200 Review...\n",
      "Processing \"Train Data\", 2300 Review...\n",
      "Processing \"Train Data\", 2400 Review...\n",
      "Processing \"Train Data\", 2500 Review...\n",
      "Processing \"Train Data\", 2600 Review...\n",
      "Processing \"Train Data\", 2700 Review...\n",
      "Processing \"Train Data\", 2800 Review...\n",
      "Processing \"Train Data\", 2900 Review...\n",
      "Processing \"Train Data\", 3000 Review...\n",
      "Processing \"Train Data\", 3100 Review...\n",
      "Processing \"Train Data\", 3200 Review...\n",
      "Processing \"Train Data\", 3300 Review...\n",
      "Processing \"Train Data\", 3400 Review...\n",
      "Processing \"Train Data\", 3500 Review...\n",
      "Processing \"Train Data\", 3600 Review...\n",
      "Processing \"Train Data\", 3700 Review...\n",
      "Processing \"Train Data\", 3800 Review...\n",
      "Processing \"Train Data\", 3900 Review...\n",
      "Processing \"Train Data\", 4000 Review...\n",
      "Processing \"Train Data\", 4100 Review...\n",
      "Processing \"Train Data\", 4200 Review...\n",
      "Processing \"Train Data\", 4300 Review...\n",
      "Processing \"Train Data\", 4400 Review...\n",
      "Processing \"Train Data\", 4500 Review...\n",
      "Processing \"Train Data\", 4600 Review...\n",
      "Processing \"Train Data\", 4700 Review...\n",
      "Processing \"Train Data\", 4800 Review...\n",
      "Processing \"Train Data\", 4900 Review...\n",
      "Processing \"Train Data\", 5000 Review...\n",
      "Processing \"Train Data\", 5100 Review...\n",
      "Processing \"Train Data\", 5200 Review...\n",
      "Processing \"Train Data\", 5300 Review...\n",
      "Processing \"Train Data\", 5400 Review...\n",
      "Processing \"Train Data\", 5500 Review...\n",
      "Processing \"Train Data\", 5600 Review...\n",
      "Processing \"Train Data\", 5700 Review...\n",
      "Processing \"Train Data\", 5800 Review...\n",
      "Processing \"Train Data\", 5900 Review...\n",
      "Processing \"Train Data\", 6000 Review...\n",
      "Processing \"Train Data\", 6100 Review...\n",
      "Processing \"Train Data\", 6200 Review...\n",
      "Processing \"Train Data\", 6300 Review...\n",
      "Processing \"Train Data\", 6400 Review...\n",
      "Processing \"Train Data\", 6500 Review...\n",
      "Processing \"Train Data\", 6600 Review...\n",
      "Processing \"Train Data\", 6700 Review...\n",
      "Processing \"Train Data\", 6800 Review...\n",
      "Processing \"Train Data\", 6900 Review...\n",
      "Processing \"Train Data\", 7000 Review...\n",
      "Processing \"Train Data\", 7100 Review...\n",
      "Processing \"Train Data\", 7200 Review...\n",
      "Processing \"Train Data\", 7300 Review...\n",
      "Processing \"Train Data\", 7400 Review...\n",
      "Processing \"Train Data\", 7500 Review...\n",
      "Processing \"Train Data\", 7600 Review...\n",
      "Processing \"Train Data\", 7700 Review...\n",
      "Processing \"Train Data\", 7800 Review...\n",
      "Processing \"Train Data\", 7900 Review...\n",
      "Processing \"Train Data\", 8000 Review...\n",
      "Processing \"Train Data\", 8100 Review...\n",
      "Processing \"Train Data\", 8200 Review...\n",
      "Processing \"Train Data\", 8300 Review...\n",
      "Processing \"Train Data\", 8400 Review...\n",
      "Processing \"Train Data\", 8500 Review...\n",
      "Processing \"Train Data\", 8600 Review...\n",
      "Processing \"Test Data\", 0 Review...\n",
      "Processing \"Test Data\", 100 Review...\n",
      "Processing \"Test Data\", 200 Review...\n",
      "Processing \"Test Data\", 300 Review...\n",
      "Processing \"Test Data\", 400 Review...\n",
      "Processing \"Test Data\", 500 Review...\n",
      "Processing \"Test Data\", 600 Review...\n",
      "Processing \"Test Data\", 700 Review...\n",
      "Processing \"Test Data\", 800 Review...\n",
      "Processing \"Test Data\", 900 Review...\n",
      "Processing \"Test Data\", 1000 Review...\n",
      "Processing \"Test Data\", 1100 Review...\n",
      "Processing \"Test Data\", 1200 Review...\n",
      "Processing \"Test Data\", 1300 Review...\n",
      "Processing \"Test Data\", 1400 Review...\n",
      "Processing \"Test Data\", 1500 Review...\n"
     ]
    }
   ],
   "source": [
    "# Train Data\n",
    "cleaned_train_data = process_data(train_data, data_type = 'Train Data')\n",
    "\n",
    "# Test Data\n",
    "cleaned_test_data = process_data(test_data, data_type = 'Test Data')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "       Id                                            Comment      Topic\n0   0x840  thing might neg frequenc depend select least c...    Biology\n1   0xbf0  hard believ exist particular detect anyth inve...    Physics\n2  0x1dfc                                                bee    Biology\n3   0xc7e  medic technician alot drug liver probabl die i...    Biology\n4   0xbba                                cesium pretti metal  Chemistry",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Comment</th>\n      <th>Topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x840</td>\n      <td>thing might neg frequenc depend select least c...</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0xbf0</td>\n      <td>hard believ exist particular detect anyth inve...</td>\n      <td>Physics</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x1dfc</td>\n      <td>bee</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0xc7e</td>\n      <td>medic technician alot drug liver probabl die i...</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0xbba</td>\n      <td>cesium pretti metal</td>\n      <td>Chemistry</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train_data.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "       Id                                            Comment      Topic\n0  0x1aa9  person idea never test howev test outdat inacc...    Biology\n1   0x25e  skeptic heavier lid need build pressur lighter...    Physics\n2  0x1248  think book subject problem conscious univers a...    Biology\n3   0x2b9  chemistri hard uni ive read somewher hardest d...  Chemistry\n4  0x24af  addit comment critic theori without check lot ...    Physics",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Comment</th>\n      <th>Topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x1aa9</td>\n      <td>person idea never test howev test outdat inacc...</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0x25e</td>\n      <td>skeptic heavier lid need build pressur lighter...</td>\n      <td>Physics</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x1248</td>\n      <td>think book subject problem conscious univers a...</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0x2b9</td>\n      <td>chemistri hard uni ive read somewher hardest d...</td>\n      <td>Chemistry</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x24af</td>\n      <td>addit comment critic theori without check lot ...</td>\n      <td>Physics</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_test_data.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "cleaned_train_reviews = cleaned_train_data['Comment']\n",
    "cleaned_test_reviews = cleaned_test_data['Comment']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## create BagOfWord vector for each sample/sentence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagOfWords of train_data shape: (8695, 15008)\n",
      "bagOfWords of test_data shape: (1586, 9726)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(cleaned_train_reviews)\n",
    "train_data_vocab = vectorizer.get_feature_names_out()\n",
    "train_data_features = train_data_features.toarray()\n",
    "dictionary_train = pd.DataFrame(data=train_data_features,columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "test_data_features = vectorizer.fit_transform(cleaned_test_reviews)\n",
    "test_data_vocab = vectorizer.get_feature_names_out()\n",
    "test_data_features = test_data_features.toarray()\n",
    "dictionary_test = pd.DataFrame(data=test_data_features,columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(f'bagOfWords of train_data shape: {train_data_features.shape}')\n",
    "print(f'bagOfWords of test_data shape: {test_data_features.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "data": {
      "text/plain": "      aah  aaps  aaronson  aat  abailable  abandon  abbreviation  abd  \\\n0       0     0         0    0          0        0             0    0   \n1       0     0         0    0          0        0             0    0   \n2       0     0         0    0          0        0             0    0   \n3       0     0         0    0          0        0             0    0   \n4       0     0         0    0          0        0             0    0   \n...   ...   ...       ...  ...        ...      ...           ...  ...   \n8690    0     0         0    0          0        0             0    0   \n8691    0     0         0    0          0        0             0    0   \n8692    0     0         0    0          0        0             0    0   \n8693    0     0         0    0          0        0             0    0   \n8694    0     0         0    0          0        0             0    0   \n\n      abdomen  abdominal  ...  zoidberg  zone  zoom  zotero  ztsi  zubairy  \\\n0           0          0  ...         0     0     0       0     0        0   \n1           0          0  ...         0     0     0       0     0        0   \n2           0          0  ...         0     0     0       0     0        0   \n3           0          0  ...         0     0     0       0     0        0   \n4           0          0  ...         0     0     0       0     0        0   \n...       ...        ...  ...       ...   ...   ...     ...   ...      ...   \n8690        0          0  ...         0     0     0       0     0        0   \n8691        0          0  ...         0     0     0       0     0        0   \n8692        0          0  ...         0     0     0       0     0        0   \n8693        0          0  ...         0     0     0       0     0        0   \n8694        0          0  ...         0     0     0       0     0        0   \n\n      zurich  zwitterion  zygomatic  zyklon  \n0          0           0          0       0  \n1          0           0          0       0  \n2          0           0          0       0  \n3          0           0          0       0  \n4          0           0          0       0  \n...      ...         ...        ...     ...  \n8690       0           0          0       0  \n8691       0           0          0       0  \n8692       0           0          0       0  \n8693       0           0          0       0  \n8694       0           0          0       0  \n\n[8695 rows x 15008 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aah</th>\n      <th>aaps</th>\n      <th>aaronson</th>\n      <th>aat</th>\n      <th>abailable</th>\n      <th>abandon</th>\n      <th>abbreviation</th>\n      <th>abd</th>\n      <th>abdomen</th>\n      <th>abdominal</th>\n      <th>...</th>\n      <th>zoidberg</th>\n      <th>zone</th>\n      <th>zoom</th>\n      <th>zotero</th>\n      <th>ztsi</th>\n      <th>zubairy</th>\n      <th>zurich</th>\n      <th>zwitterion</th>\n      <th>zygomatic</th>\n      <th>zyklon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8690</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8691</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8692</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8693</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8694</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8695 rows × 15008 columns</p>\n</div>"
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "data": {
      "text/plain": "      aapt  abandon  abandoned  abc  abdomen  abdominal  abe  ability  \\\n0        0        0          1    0        0          0    0        0   \n1        0        0          0    0        0          0    0        0   \n2        0        0          0    0        0          0    0        0   \n3        0        0          0    0        0          0    0        0   \n4        0        0          0    0        0          0    0        0   \n...    ...      ...        ...  ...      ...        ...  ...      ...   \n1581     0        0          0    0        0          0    0        0   \n1582     0        0          0    0        0          0    0        0   \n1583     0        0          0    0        0          0    0        0   \n1584     0        0          0    0        0          0    0        0   \n1585     0        0          0    0        0          0    0        0   \n\n      abinbev  abiogenesis  ...  zinc  zip  zipper  zippo  zohaib  zona  zone  \\\n0           0            0  ...     0    0       0      0       0     0     0   \n1           0            0  ...     0    0       0      0       0     0     0   \n2           0            0  ...     0    0       0      0       0     0     0   \n3           0            0  ...     0    0       0      0       0     0     0   \n4           0            0  ...     0    0       0      0       0     0     0   \n...       ...          ...  ...   ...  ...     ...    ...     ...   ...   ...   \n1581        0            0  ...     0    0       0      0       0     0     0   \n1582        0            0  ...     0    0       0      0       0     0     0   \n1583        0            0  ...     0    0       0      0       0     0     0   \n1584        0            0  ...     0    0       0      0       0     0     0   \n1585        0            0  ...     0    0       0      0       0     0     0   \n\n      zoxyz  zurich  zwicky  \n0         0       0       0  \n1         0       0       0  \n2         0       0       0  \n3         0       0       0  \n4         0       0       0  \n...     ...     ...     ...  \n1581      0       0       0  \n1582      0       0       0  \n1583      0       0       0  \n1584      0       0       0  \n1585      0       0       0  \n\n[1586 rows x 9726 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aapt</th>\n      <th>abandon</th>\n      <th>abandoned</th>\n      <th>abc</th>\n      <th>abdomen</th>\n      <th>abdominal</th>\n      <th>abe</th>\n      <th>ability</th>\n      <th>abinbev</th>\n      <th>abiogenesis</th>\n      <th>...</th>\n      <th>zinc</th>\n      <th>zip</th>\n      <th>zipper</th>\n      <th>zippo</th>\n      <th>zohaib</th>\n      <th>zona</th>\n      <th>zone</th>\n      <th>zoxyz</th>\n      <th>zurich</th>\n      <th>zwicky</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1581</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1582</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1583</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1584</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1585</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1586 rows × 9726 columns</p>\n</div>"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['aah', 'aap', 'aaronson', ..., 'zwitterion', 'zygomat', 'zyklon'],\n      dtype=object)"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['aapt', 'abandon', 'abc', ..., 'zoxyz', 'zurich', 'zwicki'],\n      dtype=object)"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "# model_w2v = api.load(\"word2vec-google-news-300\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "w2v_model_google=KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_30204\\2713069799.py:10: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_sentances = list_of_sentance(cleaned_train_reviews.append(cleaned_test_reviews))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('general', 0.9994341135025024), ('best', 0.9994133710861206), ('professor', 0.9993730187416077), ('course', 0.9992820620536804), ('university', 0.9992630481719971), ('easy', 0.9992470741271973), ('looking', 0.999234139919281), ('program', 0.9992258548736572), ('went', 0.9991999268531799), ('start', 0.9991911053657532)]\n",
      "==================================================\n",
      "[('instead', 0.9991294741630554), ('scientist', 0.9991053342819214), ('random', 0.9991041421890259), ('remember', 0.9990876913070679), ('leave', 0.9990850687026978), ('method', 0.9990643262863159), ('nit', 0.999058187007904), ('towards', 0.9990547895431519), ('mix', 0.9990513920783997), ('particular', 0.9990360140800476)]\n"
     ]
    }
   ],
   "source": [
    "def list_of_sentence(data):\n",
    "    list_of_sentence=[]\n",
    "    for sentence in data:\n",
    "        list_of_sentence.append(sentence.split())\n",
    "    return list_of_sentence\n",
    "\n",
    "train_sentences = list_of_sentence(cleaned_train_reviews)\n",
    "test_sentences = list_of_sentence(cleaned_test_reviews)\n",
    "all_sentences = list_of_sentence(cleaned_train_reviews.append(cleaned_test_reviews))\n",
    "# Train Word2Vec model using own text corpus\n",
    "# min_count = 5 considers only words that occured atleast 5 times\n",
    "w2v_model=Word2Vec(all_sentences,min_count=5, workers=16)\n",
    "print(w2v_model.wv.most_similar('great'))\n",
    "print('='*50)\n",
    "print(w2v_model.wv.most_similar('worst'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "3000000"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_model_google)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('terrific', 0.7989331483840942), ('fantastic', 0.7935212254524231), ('tremendous', 0.7748855352401733), ('wonderful', 0.7647868990898132), ('good', 0.7291510105133057), ('incredible', 0.7032873630523682), ('marvelous', 0.6971103549003601), ('phenomenal', 0.6841564178466797), ('amazing', 0.663412868976593), ('awesome', 0.6510507464408875)]\n",
      "==================================================\n",
      "[('Worst', 0.6146091818809509), ('weakest', 0.6143776774406433), ('scariest', 0.5957257747650146), ('ugliest', 0.5931181311607361), ('best', 0.5835111141204834), ('bleakest', 0.5718506574630737), ('strongest', 0.567145586013794), ('nastiest', 0.5644308924674988), ('lousiest', 0.563145101070404), ('toughest', 0.5624396204948425)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model_google.most_similar('great'))\n",
    "print('='*50)\n",
    "print(w2v_model_google.most_similar('worst'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words that occured minimum 1 times  5111\n",
      "sample words  ['like', 'one', 'get', 'time', 'think', 'know', 'make', 'thing', 'people', 'much', 'even', 'way', 'need', 'really', 'http', 'good', 'see', 'water', 'energy', 'work', 'look', 'lot', 'well', 'say', 'use', 'want', 'something', 'question', 'mean', 'year', 'doe', 'physic', 'chemistry', 'different', 'still', 'first', 'acid', 'sure', 'right', 'probably', 'point', 'com', 'actually', 'take', 'light', 'many', 'cell', 'used', 'going', 'yes']\n"
     ]
    }
   ],
   "source": [
    "w2v_words = list(w2v_model.wv.index_to_key)\n",
    "print(\"number of words that occured minimum 1 times \",len(w2v_words))\n",
    "print(\"sample words \", w2v_words[0:50])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "3000000"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_words_google = w2v_model_google.index_to_key\n",
    "len(w2v_words_google)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BagOfWord weighted Word2Vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [],
   "source": [
    "def bagOfWord_W2V(vocab, list_of_sentence, dictionary):\n",
    "    bagOfWord_feat = vocab\n",
    "    # average Word2Vec\n",
    "    # compute average word2vec for each review.\n",
    "    sent_vectors = [] # the avg-w2v for each sentence/review is stored in this list\n",
    "    index = 0\n",
    "    for sent in tqdm(list_of_sentence): # for each review/sentence\n",
    "        sent_vec = np.zeros(300) # as word vectors are of zero length 300, because of google's w2v len\n",
    "        weight_sum = 0 # sum of bagOfWords value in each sentence\n",
    "        for word in sent: # for each word in a review/sentence\n",
    "            if word in w2v_model_google and word in bagOfWord_feat:\n",
    "                vec = w2v_model_google.get_vector(word)\n",
    "                bagOfWord = dictionary[word][index]\n",
    "                sent_vec += (vec * bagOfWord)\n",
    "                weight_sum += bagOfWord\n",
    "        if weight_sum != 0:\n",
    "            sent_vec /= weight_sum\n",
    "        sent_vectors.append(sent_vec)\n",
    "        index +=1\n",
    "    print(len(sent_vectors))\n",
    "    print(len(sent_vectors[0]))\n",
    "    return sent_vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8695/8695 [00:39<00:00, 218.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8695\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_vectors = bagOfWord_W2V(train_data_vocab,train_sentences,dictionary_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1586/1586 [00:12<00:00, 126.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1586\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectors = bagOfWord_W2V(test_data_vocab,test_sentences,dictionary_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.01254547,  0.13848013, -0.01803002,  0.08739342, -0.04472589,\n        0.00048431,  0.05416744, -0.05495731,  0.07713388,  0.10639147,\n       -0.00712031, -0.05167357, -0.04313136, -0.00721968, -0.07203605,\n        0.02632601, -0.00618012,  0.05110635, -0.02639979, -0.07857214,\n       -0.05100525, -0.00830343, -0.03077892, -0.05105616, -0.03915834,\n       -0.00522298, -0.03271245,  0.09246807,  0.04016429,  0.02971231,\n       -0.04862932,  0.01250288,  0.025833  , -0.03726972, -0.05463933,\n       -0.05113186, -0.08419762, -0.04065027,  0.0473252 ,  0.05688174,\n        0.09554675, -0.04845523,  0.07713942,  0.05663325,  0.00647396,\n       -0.11810467,  0.00810179,  0.03024089, -0.02047982,  0.03069665,\n       -0.03979751,  0.00359608, -0.00052119, -0.02281864, -0.01315536,\n        0.02058398, -0.03308471, -0.04606974,  0.03149596, -0.03864559,\n       -0.09191119,  0.02206808, -0.09069931, -0.04027223,  0.03246112,\n       -0.01728606, -0.01092933,  0.02626202,  0.00596683,  0.07429177,\n        0.04014499,  0.03876653,  0.08155419,  0.04492673, -0.06892849,\n       -0.01016815,  0.08498036,  0.0211705 ,  0.02519478,  0.02006588,\n        0.02540034, -0.06459033,  0.01021081,  0.00676286, -0.00080972,\n        0.02993226, -0.09149687,  0.06731232,  0.03025339,  0.05747734,\n        0.06833333,  0.05786186, -0.08725757, -0.09609052, -0.07879029,\n       -0.03877971,  0.01459604,  0.03747804,  0.08775935, -0.02350787,\n       -0.006309  , -0.04211467, -0.00470775,  0.00353317, -0.071596  ,\n       -0.05607725, -0.03839453, -0.00797228, -0.02121462, -0.05152534,\n       -0.07114972, -0.02548319,  0.02536313, -0.03432886,  0.15886821,\n        0.00841276,  0.07490956, -0.07123231, -0.00453363,  0.04460863,\n       -0.04022267, -0.00794996, -0.08068015, -0.02718416,  0.02822928,\n        0.00849289,  0.01405915, -0.0231456 ,  0.0056559 ,  0.02058108,\n       -0.06470332, -0.10489737, -0.01942847, -0.00904079, -0.06506259,\n       -0.03405068,  0.00785115, -0.00668133,  0.01722592,  0.0883081 ,\n        0.07567699, -0.06600804,  0.00834214,  0.02653302,  0.0362368 ,\n       -0.02830002, -0.06378703, -0.000257  , -0.0870415 , -0.09857455,\n        0.04038194, -0.10555173, -0.08648839,  0.03373756, -0.0508926 ,\n       -0.05817404, -0.00416313, -0.04180114, -0.02606102, -0.04122145,\n        0.02451438,  0.07616765,  0.03105292, -0.03329972,  0.02400644,\n       -0.05869287,  0.081433  , -0.04838255,  0.00724755, -0.00229014,\n       -0.13032713, -0.00502213, -0.05608828, -0.0926781 , -0.03836337,\n        0.01633296,  0.088147  , -0.08554805, -0.011605  , -0.01820506,\n       -0.08063984, -0.04846532, -0.01529156, -0.03226528, -0.02067307,\n       -0.01481918, -0.02864187, -0.00063873,  0.06177155,  0.02779357,\n        0.01094878, -0.0371182 , -0.06343482, -0.04789469,  0.03234655,\n        0.0833594 ,  0.0203725 , -0.03437767, -0.08394515, -0.03183273,\n        0.00751811,  0.07368589, -0.01732818, -0.03244435,  0.04112036,\n       -0.05913563, -0.00343777, -0.01526878,  0.00130986,  0.03630154,\n       -0.01840147,  0.0444661 , -0.03445252,  0.02306347, -0.08591467,\n       -0.0049849 ,  0.08958618, -0.06075104, -0.04766961,  0.04128297,\n       -0.04215991,  0.03778732,  0.01167606,  0.01765259,  0.01550671,\n       -0.10548666,  0.04623378, -0.00692219, -0.01327335,  0.02163703,\n       -0.01192747,  0.01697717,  0.03478083,  0.00919683, -0.01245123,\n        0.01027961, -0.02704229, -0.10696764,  0.1066776 ,  0.07034277,\n        0.09333171,  0.03572713,  0.01248377, -0.06827574, -0.02976782,\n       -0.01657549, -0.0042794 ,  0.03827919, -0.02667784, -0.02416445,\n       -0.02859585,  0.01676323,  0.03235387,  0.0770764 ,  0.0512636 ,\n       -0.03099029,  0.01459658,  0.03979921, -0.06962655, -0.01719473,\n        0.00288265, -0.00931473,  0.00099119, -0.00059988,  0.05598336,\n        0.09593667, -0.05903039, -0.01740366, -0.05437369, -0.05013767,\n        0.03135618,  0.01724535,  0.08587955,  0.02219759,  0.05240019,\n       -0.03408902, -0.0718563 , -0.06432283, -0.04958678, -0.00425972,\n        0.00292638,  0.04613022,  0.05141138,  0.04434999,  0.07279557,\n       -0.03687967, -0.04833171,  0.03367363,  0.02714085,  0.02380634,\n       -0.0178377 ,  0.07598262, -0.09590258, -0.00449674, -0.01131458,\n       -0.06253605, -0.03083511, -0.00130727,  0.04867248, -0.00327982])"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 1000)\n",
    "\n",
    "X = train_vectors\n",
    "Y = cleaned_train_data['Topic']\n",
    "clf = clf.fit(X, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7622950819672131"
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(test_vectors)\n",
    "y_true = cleaned_test_data['Topic']\n",
    "accuracy_score(y_true, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing \"sample\", 0 Review...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 499.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "300\n",
      "['Chemistry']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "comment = \"Acids, bases, and pH are concepts that apply to aqueous solutions (solutions in water). pH refers to the hydrogen ion concentration, or the ability of a species to donate/accept protons or electrons. Acids and bases reflect the relative availability of hydrogen ions or proton/electron donors or acceptors. Acid-base reactions are extremely important in living cells and industrial processes.\"\n",
    "\n",
    "sample = pd.DataFrame({'Comment':[comment]})\n",
    "sample = process_data(sample,'sample')\n",
    "\n",
    "sample_features = vectorizer.fit_transform(sample['Comment']).toarray()\n",
    "sample_vocab = vectorizer.get_feature_names_out()\n",
    "dictionary_sample = pd.DataFrame(data=sample_features,columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "sample_sentances = list_of_sentence(sample['Comment'])\n",
    "\n",
    "sample_vector = bagOfWord_W2V(sample_vocab,sample_sentances,dictionary_sample)\n",
    "\n",
    "print(clf.predict(sample_vector))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "def bagOfWord_W2V(vocab, list_of_sentence, dictionary):\n",
    "    bagOfWord_feat = vocab\n",
    "    # average Word2Vec\n",
    "    # compute average word2vec for each review.\n",
    "    sent_vectors = [] # the avg-w2v for each sentence/review is stored in this list\n",
    "    index = 0\n",
    "    for sent in tqdm(list_of_sentence): # for each review/sentence\n",
    "        sent_vec = np.zeros(100) # as word vectors are of zero length 50,\n",
    "        #you might need to change this to 300 if you use google's w2v\n",
    "        cnt_words =0 # num of words with a valid vector in the sentence/review\n",
    "        for word in sent: # for each word in a review/sentence\n",
    "            if word in w2v_words and word in bagOfWord_feat:\n",
    "                vec = w2v_model.wv[word]\n",
    "                bagOfWord = dictionary[word][index]\n",
    "                sent_vec += (vec * bagOfWord)\n",
    "                cnt_words += bagOfWord\n",
    "        if cnt_words != 0:\n",
    "            sent_vec /= cnt_words\n",
    "        sent_vectors.append(sent_vec)\n",
    "        index +=1\n",
    "    print(len(sent_vectors))\n",
    "    print(len(sent_vectors[0]))\n",
    "    return sent_vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8695/8695 [00:44<00:00, 196.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8695\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_vectors = bagOfWord_W2V(train_data_vocab,train_sentences,dictionary_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1586/1586 [00:13<00:00, 114.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1586\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectors = bagOfWord_W2V(test_data_vocab,test_sentences,dictionary_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 1000)\n",
    "\n",
    "X = train_vectors\n",
    "Y = cleaned_train_data['Topic']\n",
    "clf = clf.fit(X, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "data": {
      "text/plain": "0.617906683480454"
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(test_vectors)\n",
    "y_true = cleaned_test_data['Topic']\n",
    "accuracy_score(y_true, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}